{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get padded cds and transcript sequences for transcript set chosen with ORFquant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:15.201572Z",
     "start_time": "2020-11-25T02:28:14.958555Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "def convertFastaToDict(fastaFile):\n",
    "    '''\n",
    "    converts a fasta file to a dict of {sequenceName:sequence}\n",
    "    can take extra files in * args\n",
    "    '''\n",
    "    if isinstance(fastaFile, list):\n",
    "        files = fastaFile\n",
    "    else:\n",
    "        files = [fastaFile]\n",
    "    currentName = None\n",
    "    currentSequence = None\n",
    "    seqDict = {}\n",
    "    for currentFile in files:\n",
    "        if currentFile.endswith('.gz'):\n",
    "            import gzip\n",
    "            f = gzip.open(currentFile)\n",
    "        else:\n",
    "            f = open(currentFile)\n",
    "        for line in f:\n",
    "            if not line.strip() == '' and not line.startswith('#'):  # ignore empty lines and commented out lines\n",
    "                if line.startswith('>'):  # > marks the start of a new sequence\n",
    "                    if not currentName == None:  # after we've reached the firtst > line, we know what the sequence corresponds to\n",
    "                        seqDict[currentName] = currentSequence\n",
    "                    currentName = line.strip()[1:].split()[\n",
    "                        0]  # i've noticed the gencode names have extraneous numbering after some whitespace. This doens't match the GTF files, so I'm removing it.\n",
    "                    currentSequence = ''\n",
    "                else:\n",
    "                    currentSequence += line.strip()\n",
    "        f.close()\n",
    "    seqDict[currentName] = currentSequence\n",
    "    return seqDict\n",
    "\n",
    "def get_CDS_seq(transcript, pad_5p, pad_3p):\n",
    "    transcript_seq = transcript_seqs[transcript].upper()\n",
    "    info_parts = transcript.split('|')\n",
    "    for info_part in info_parts:\n",
    "        if info_part.startswith('CDS:'):\n",
    "            #print info_part, transcript\n",
    "            CDS_positions = [int(pos) for pos in info_part.split(':')[1].split('-')]\n",
    "            CDS_seq = transcript_seq[max((CDS_positions[0]-1)-pad_5p, 0):CDS_positions[1]+pad_3p]\n",
    "            return CDS_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:25.635991Z",
     "start_time": "2020-11-25T02:28:15.205955Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
      "                                 Dload  Upload   Total   Spent    Left  Speed\n",
      "100 41.5M  100 41.5M    0     0  4819k      0  0:00:08  0:00:08 --:--:-- 6069k\n"
     ]
    }
   ],
   "source": [
    "#download transcript sequences from gencode\n",
    "! curl -L ftp://ftp.ebi.ac.uk/pub/databases/gencode/Gencode_human/release_35/gencode.v35.pc_transcripts.fa.gz -o ../annotations/gencode.v35.pc_transcripts.fa.gz\n",
    "! gunzip -c ../annotations/gencode.v35.pc_transcripts.fa.gz | cat - ../annotations/reporter/UGAC_reporter_transcript.fa > ../annotations/gencode.v35.pBZ105.pc_transcripts.fa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:27.688090Z",
     "start_time": "2020-11-25T02:28:25.642758Z"
    }
   },
   "outputs": [],
   "source": [
    "transcript_seqs = convertFastaToDict('../annotations/gencode.v35.pBZ105.pc_transcripts.fa')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:27.705913Z",
     "start_time": "2020-11-25T02:28:27.696619Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_tx_from_file(file_name):\n",
    "    txs = set()\n",
    "    f = open(file_name)\n",
    "    for line in f:\n",
    "        txs.add(line.strip())\n",
    "    f.close()\n",
    "    return txs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:27.725065Z",
     "start_time": "2020-11-25T02:28:27.711165Z"
    }
   },
   "outputs": [],
   "source": [
    "def write_padded_CDS_seqs(transcript_file, outfile_name, pad_5p, pad_3p):\n",
    "    transcript_subset = get_tx_from_file(transcript_file)\n",
    "    outfile = open(outfile_name, 'w')\n",
    "    for transcript in transcript_seqs.keys():\n",
    "        if transcript.split('|')[0] in transcript_subset:\n",
    "            cds_seq = get_CDS_seq(transcript, pad_5p, pad_3p)\n",
    "            outfile.write('>%s\\n%s\\n' % (transcript, cds_seq))\n",
    "    outfile.close()\n",
    "\n",
    "def write_subset_tx_seqs(transcript_file, outfile_name):\n",
    "    transcript_subset = get_tx_from_file(transcript_file)\n",
    "    outfile = open(outfile_name, 'w')\n",
    "    for transcript in transcript_seqs.keys():\n",
    "        if transcript.split('|')[0] in transcript_subset:\n",
    "            outfile.write('>%s\\n%s\\n' % (transcript, transcript_seqs[transcript]))\n",
    "    outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:27.734055Z",
     "start_time": "2020-11-25T02:28:27.729370Z"
    }
   },
   "outputs": [],
   "source": [
    "tx_file = '../1_orfquant/orfquant_tx_stops_collapsed.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:28.372430Z",
     "start_time": "2020-11-25T02:28:27.738297Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "write_padded_CDS_seqs(tx_file, os.path.join('../annotations/', 'orfquant_CDS_%d_%d.fa' % (15, 15)),15, 15)\n",
    "write_subset_tx_seqs(tx_file, '../annotations/orfquant_tx.fa')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate salmon indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:28:30.312383Z",
     "start_time": "2020-11-25T02:28:28.376406Z"
    }
   },
   "outputs": [],
   "source": [
    "#generate decoys list, which just contains a list of human chromosome names\n",
    "! grep \"^>\" < ../annotations/genome/GRCh38.primary_assembly.genome.pBZ105.fa | cut -d \" \" -f 1 > decoys.txt\n",
    "! sed -i.bak -e 's/>//g' decoys.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T02:39:01.497532Z",
     "start_time": "2020-11-25T02:28:30.318612Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘gentromes’: File exists\n",
      "cat ../annotations/orfquant_CDS_15_15.fa ../annotations/genome/GRCh38.primary_assembly.genome.pBZ105.fa | gzip > gentromes/orfquant_CDS_15_15.gentrome.fa.gz\n",
      "cat ../annotations/orfquant_tx.fa ../annotations/genome/GRCh38.primary_assembly.genome.pBZ105.fa | gzip > gentromes/orfquant_tx.gentrome.fa.gz\n"
     ]
    }
   ],
   "source": [
    "#now generate \"gentrome\" files, which concatenate the genome and transcriptome\n",
    "!mkdir gentromes\n",
    "import os\n",
    "import subprocess\n",
    "for tx_file in ['orfquant_CDS_15_15.fa', 'orfquant_tx.fa']:\n",
    "    tx_path = os.path.join('../annotations/', tx_file)\n",
    "    prefix = tx_file[:-3]\n",
    "    gentrome_path = os.path.join('gentromes/', prefix+'.gentrome.fa.gz')\n",
    "    cmd=\"cat {tx_path} ../annotations/genome/GRCh38.primary_assembly.genome.pBZ105.fa | gzip > {gentrome_path}\".format(**locals())\n",
    "    print(cmd)\n",
    "    #subprocess.Popen(cmd, shell=True).wait()\n",
    "    ! {cmd}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-25T05:09:44.137064Z",
     "start_time": "2020-11-25T02:39:01.505503Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mkdir: cannot create directory ‘indices’: File exists\n",
      "salmon index -t gentromes/orfquant_CDS_15_15.gentrome.fa.gz -d decoys.txt t -p 40 -i indices/orfquant_CDS_15_15_k13 -k 13 --gencode \n",
      "Version Info: This is the most recent version of salmon.\n",
      "[2020-11-24 21:39:01.728] [jLog] [info] building index\n",
      "out : indices/orfquant_CDS_15_15_k13\n",
      "\u001b[00m[2020-11-24 21:39:01.728] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2020-11-24 21:40:18.465] [puff::index::jointLog] [warning] Removed 90 transcripts that were sequence duplicates of indexed transcripts.\n",
      "\u001b[00m\u001b[35m[2020-11-24 21:40:18.465] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag\n",
      "\u001b[00m\u001b[00m[2020-11-24 21:40:18.466] [puff::index::jointLog] [info] Replaced 151,122,963 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2020-11-24 21:40:18.466] [puff::index::jointLog] [info] Clipped poly-A tails from 3 transcripts\n",
      "\u001b[00mwrote 24440 cleaned references\n",
      "\u001b[00m[2020-11-24 21:40:22.963] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2020-11-24 21:40:57.170] [puff::index::jointLog] [info] ntHll estimated 35642314 distinct k-mers, setting filter size to 2^30\n",
      "\u001b[00mThreads = 40\n",
      "Vertex length = 13\n",
      "Hash functions = 5\n",
      "Filter size = 1073741824\n",
      "Capacity = 1\n",
      "Files: \n",
      "indices/orfquant_CDS_15_15_k13/ref_k13_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:1073741824\n",
      "Pass\tFilling\tFiltering\n",
      "1\t46\t196\t\n",
      "2\t89\t9\n",
      "True junctions count = 33452488\n",
      "False junctions count = 8936\n",
      "Hash table size = 33461424\n",
      "Candidate marks count = 3131008841\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 12\n",
      "True marks count: 3130997634\n",
      "Edges construction time: 207\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 33452488\n",
      "\n",
      "allowedIn: 30\n",
      "Max Junction ID: 33452488\n",
      "seen.size():267619913 kmerInfo.size():33452489\n",
      "approximateContigTotalLength: 466192477\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=33286086 | (succ>1 & isStart)=5 | (prec>1 & isEnd)=4 | (isStart & isEnd)=0\n",
      "contig count: 33539655 element count: 436017456 complex nodes: 33286095\n",
      "# of ones in rank vector: 33539654\n",
      "\u001b[00m[2020-11-24 22:19:07.611] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:19:07.611] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory indices/orfquant_CDS_15_15_k13\n",
      "\u001b[00msize = 436017456\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 51.747 ms\n",
      "-----------------------------------------\n",
      "size = 436017456\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 25.971 ms\n",
      "-----------------------------------------\n",
      "Number of ones: 33539654\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 65508\n",
      "33539654\n",
      "\u001b[00m[2020-11-24 22:19:08.703] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:19:09.902] [puff::index::jointLog] [info] contig count for validation: 33,539,654\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:21:39.630] [puff::index::jointLog] [info] Total # of Contigs : 33,539,654\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:21:39.630] [puff::index::jointLog] [info] Total # of numerical Contigs : 33,539,654\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:22:35.894] [puff::index::jointLog] [info] Total # of contig vec entries: 3,131,105,095\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:22:35.894] [puff::index::jointLog] [info] bits per offset entry 32\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:34:43.641] [puff::index::jointLog] [info] Done constructing the contig vector. 33539655\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:27.711] [puff::index::jointLog] [info] # segments = 33,539,654\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:27.711] [puff::index::jointLog] [info] total length = 436,017,456\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:28.067] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:42.768] [puff::index::jointLog] [info] positional integer width = 29\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:42.768] [puff::index::jointLog] [info] seqSize = 436,017,456\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:42.768] [puff::index::jointLog] [info] rankSize = 436,017,456\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:42.768] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:42.768] [puff::index::jointLog] [info] num keys = 33,541,608\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   0 min 3  sec   remaining:   0 min 0  sec\n",
      "Bitarray       175752896  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2020-11-24 22:36:45.488] [puff::index::jointLog] [info] mphf size = 20.9514 MB\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk size = 10,900,437\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 0 = [0, 10,900,439)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 1 = [10,900,439, 21,800,876)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 2 = [21,800,876, 32,701,325)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 3 = [32,701,325, 43,601,762)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 4 = [43,601,762, 54,502,200)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 5 = [54,502,200, 65,402,649)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 6 = [65,402,649, 76,303,086)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 7 = [76,303,086, 87,203,523)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 8 = [87,203,523, 98,103,972)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 9 = [98,103,972, 109,004,410)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 10 = [109,004,410, 119,904,855)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 11 = [119,904,855, 130,805,304)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 12 = [130,805,304, 141,705,744)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 13 = [141,705,744, 152,606,181)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 14 = [152,606,181, 163,506,619)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 15 = [163,506,619, 174,407,062)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.574] [puff::index::jointLog] [info] chunk 16 = [174,407,062, 185,307,510)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 17 = [185,307,510, 196,207,947)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 18 = [196,207,947, 207,108,386)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 19 = [207,108,386, 218,008,824)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 20 = [218,008,824, 228,909,272)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 21 = [228,909,272, 239,809,720)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 22 = [239,809,720, 250,710,159)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 23 = [250,710,159, 261,610,596)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 24 = [261,610,596, 272,511,033)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 25 = [272,511,033, 283,411,470)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 26 = [283,411,470, 294,311,919)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 27 = [294,311,919, 305,212,362)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 28 = [305,212,362, 316,112,801)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 29 = [316,112,801, 327,013,239)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 30 = [327,013,239, 337,913,684)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 31 = [337,913,684, 348,814,130)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 32 = [348,814,130, 359,714,573)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 33 = [359,714,573, 370,615,017)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 34 = [370,615,017, 381,515,464)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 35 = [381,515,464, 392,415,901)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 36 = [392,415,901, 403,316,344)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 37 = [403,316,344, 414,216,783)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 38 = [414,216,783, 425,117,221)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.575] [puff::index::jointLog] [info] chunk 39 = [425,117,221, 436,017,444)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.895] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:45.895] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:36:46.031] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2020-11-24 22:36:47.565] [jLog] [info] done building index\n",
      "salmon index -t gentromes/orfquant_CDS_15_15.gentrome.fa.gz -d decoys.txt t -p 40 -i indices/orfquant_CDS_15_15_k31 -k 31 --gencode \n",
      "Version Info: This is the most recent version of salmon.\n",
      "[2020-11-24 22:36:47.798] [jLog] [info] building index\n",
      "out : indices/orfquant_CDS_15_15_k31\n",
      "\u001b[00m[2020-11-24 22:36:47.798] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\u001b[35m[2020-11-24 22:36:47.916] [puff::index::jointLog] [warning] Entry with header [ENST00000586354.1|ENSG00000267179.1|OTTHUMG00000182304.1|OTTHUMT00000460445.1|AC008770.2-204|AC008770.2|775|CDS:1-12|UTR3:13-775|], had length less than equal to the k-mer length of 31 (perhaps after poly-A clipping)\n",
      "\u001b[00m\n",
      "\u001b[35m[2020-11-24 22:38:04.066] [puff::index::jointLog] [warning] Removed 90 transcripts that were sequence duplicates of indexed transcripts.\n",
      "\u001b[00m\u001b[35m[2020-11-24 22:38:04.066] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:38:04.067] [puff::index::jointLog] [info] Replaced 151,122,963 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:38:04.067] [puff::index::jointLog] [info] Clipped poly-A tails from 3 transcripts\n",
      "\u001b[00mwrote 24439 cleaned references\n",
      "\u001b[00m[2020-11-24 22:38:08.661] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:38:42.799] [puff::index::jointLog] [info] ntHll estimated 2622185046 distinct k-mers, setting filter size to 2^36\n",
      "\u001b[00mThreads = 40\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 68719476736\n",
      "Capacity = 2\n",
      "Files: \n",
      "indices/orfquant_CDS_15_15_k31/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:68719476736\n",
      "Pass\tFilling\tFiltering\n",
      "1\t79\t86\t\n",
      "2\t47\t8\n",
      "True junctions count = 21523087\n",
      "False junctions count = 5072949\n",
      "Hash table size = 26596036\n",
      "Candidate marks count = 350366973\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 10\n",
      "True marks count: 345000668\n",
      "Edges construction time: 60\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 21523087\n",
      "\n",
      "allowedIn: 30\n",
      "Max Junction ID: 21527148\n",
      "seen.size():172217193 kmerInfo.size():21527149\n",
      "approximateContigTotalLength: 1192326773\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=5262976 | (succ>1 & isStart)=251 | (prec>1 & isEnd)=237 | (isStart & isEnd)=3\n",
      "contig count: 36218530 element count: 3742476724 complex nodes: 5263467\n",
      "# of ones in rank vector: 36218529\n",
      "\u001b[00m[2020-11-24 22:49:46.327] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:49:46.327] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory indices/orfquant_CDS_15_15_k31\n",
      "\u001b[00msize = 3742476724\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 443.1 ms\n",
      "-----------------------------------------\n",
      "size = 3742476724\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 217.93 ms\n",
      "-----------------------------------------\n",
      "Number of ones: 36218529\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 70740\n",
      "36218529\n",
      "\u001b[00m[2020-11-24 22:49:55.875] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:49:56.490] [puff::index::jointLog] [info] contig count for validation: 36,218,529\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:10.614] [puff::index::jointLog] [info] Total # of Contigs : 36,218,529\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:10.614] [puff::index::jointLog] [info] Total # of numerical Contigs : 36,218,529\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:13.136] [puff::index::jointLog] [info] Total # of contig vec entries: 358,468,926\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:13.137] [puff::index::jointLog] [info] bits per offset entry 29\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:35.987] [puff::index::jointLog] [info] Done constructing the contig vector. 36218530\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:48.024] [puff::index::jointLog] [info] # segments = 36,218,529\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:48.024] [puff::index::jointLog] [info] total length = 3,742,476,724\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:50:48.385] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:51:00.222] [puff::index::jointLog] [info] positional integer width = 32\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:51:00.222] [puff::index::jointLog] [info] seqSize = 3,742,476,724\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:51:00.222] [puff::index::jointLog] [info] rankSize = 3,742,476,724\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:51:00.222] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:51:00.222] [puff::index::jointLog] [info] num keys = 2,655,920,854\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   1 min 52 sec   remaining:   0 min 0  sec\n",
      "Bitarray     13916180416  bits (100.00 %)   (array + ranks )\n",
      "final hash        504000  bits (0.00 %) (nb in final hash 1500)\n",
      "\u001b[00m[2020-11-24 22:52:52.453] [puff::index::jointLog] [info] mphf size = 1659 MB\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk size = 93,561,919\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 0 = [0, 93,561,919)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 1 = [93,561,919, 187,123,838)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 2 = [187,123,838, 280,685,780)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 3 = [280,685,780, 374,247,712)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 4 = [374,247,712, 467,809,633)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 5 = [467,809,633, 561,371,552)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 6 = [561,371,552, 654,933,486)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 7 = [654,933,486, 748,495,433)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 8 = [748,495,433, 842,057,352)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 9 = [842,057,352, 935,619,271)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 10 = [935,619,271, 1,029,181,193)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 11 = [1,029,181,193, 1,122,743,112)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 12 = [1,122,743,112, 1,216,305,031)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.705] [puff::index::jointLog] [info] chunk 13 = [1,216,305,031, 1,309,866,950)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 14 = [1,309,866,950, 1,403,428,869)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 15 = [1,403,428,869, 1,496,990,790)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 16 = [1,496,990,790, 1,590,552,709)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 17 = [1,590,552,709, 1,684,114,628)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 18 = [1,684,114,628, 1,777,676,572)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 19 = [1,777,676,572, 1,871,238,491)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 20 = [1,871,238,491, 1,964,800,420)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 21 = [1,964,800,420, 2,058,362,339)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 22 = [2,058,362,339, 2,151,924,258)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 23 = [2,151,924,258, 2,245,486,177)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 24 = [2,245,486,177, 2,339,048,096)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 25 = [2,339,048,096, 2,432,610,015)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 26 = [2,432,610,015, 2,526,171,934)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.717] [puff::index::jointLog] [info] chunk 27 = [2,526,171,934, 2,619,733,853)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 28 = [2,619,733,853, 2,713,295,772)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 29 = [2,713,295,772, 2,806,857,701)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 30 = [2,806,857,701, 2,900,419,631)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 31 = [2,900,419,631, 2,993,981,550)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 32 = [2,993,981,550, 3,087,543,469)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 33 = [3,087,543,469, 3,181,105,388)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 34 = [3,181,105,388, 3,274,667,307)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 35 = [3,274,667,307, 3,368,229,226)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 36 = [3,368,229,226, 3,461,791,145)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 37 = [3,461,791,145, 3,555,353,064)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 38 = [3,555,353,064, 3,648,914,983)\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:52:57.718] [puff::index::jointLog] [info] chunk 39 = [3,648,914,983, 3,742,476,694)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[00m\u001b[00m[2020-11-24 22:53:30.067] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:53:30.067] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:53:44.879] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2020-11-24 22:53:45.957] [jLog] [info] done building index\n",
      "salmon index -t gentromes/orfquant_tx.gentrome.fa.gz -d decoys.txt t -p 40 -i indices/orfquant_tx_k13 -k 13 --gencode \n",
      "Version Info: This is the most recent version of salmon.\n",
      "[2020-11-24 22:53:46.151] [jLog] [info] building index\n",
      "out : indices/orfquant_tx_k13\n",
      "\u001b[00m[2020-11-24 22:53:46.151] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2020-11-24 22:55:02.697] [puff::index::jointLog] [warning] Removed 18 transcripts that were sequence duplicates of indexed transcripts.\n",
      "\u001b[00m\u001b[35m[2020-11-24 22:55:02.697] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:55:02.697] [puff::index::jointLog] [info] Replaced 151,122,963 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:55:02.697] [puff::index::jointLog] [info] Clipped poly-A tails from 221 transcripts\n",
      "\u001b[00mwrote 24512 cleaned references\n",
      "\u001b[00m[2020-11-24 22:55:07.653] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2020-11-24 22:55:42.191] [puff::index::jointLog] [info] ntHll estimated 35642314 distinct k-mers, setting filter size to 2^30\n",
      "\u001b[00mThreads = 40\n",
      "Vertex length = 13\n",
      "Hash functions = 5\n",
      "Filter size = 1073741824\n",
      "Capacity = 1\n",
      "Files: \n",
      "indices/orfquant_tx_k13/ref_k13_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:1073741824\n",
      "Pass\tFilling\tFiltering\n",
      "1\t46\t200\t\n",
      "2\t89\t9\n",
      "True junctions count = 33452546\n",
      "False junctions count = 14584\n",
      "Hash table size = 33467130\n",
      "Candidate marks count = 3168657632\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 10\n",
      "True marks count: 3168639296\n",
      "Edges construction time: 201\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 33452546\n",
      "\n",
      "allowedIn: 30\n",
      "Max Junction ID: 33452546\n",
      "seen.size():267620377 kmerInfo.size():33452547\n",
      "approximateContigTotalLength: 466194199\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=33286215 | (succ>1 & isStart)=3 | (prec>1 & isEnd)=6 | (isStart & isEnd)=0\n",
      "contig count: 33539666 element count: 436017596 complex nodes: 33286224\n",
      "# of ones in rank vector: 33539665\n",
      "\u001b[00m[2020-11-24 23:34:22.175] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:34:22.175] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory indices/orfquant_tx_k13\n",
      "\u001b[00msize = 436017596\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 52.852 ms\n",
      "-----------------------------------------\n",
      "size = 436017596\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 26.566 ms\n",
      "-----------------------------------------\n",
      "Number of ones: 33539665\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 65508\n",
      "33539665\n",
      "\u001b[00m[2020-11-24 23:34:23.247] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:34:24.447] [puff::index::jointLog] [info] contig count for validation: 33,539,665\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:36:55.663] [puff::index::jointLog] [info] Total # of Contigs : 33,539,665\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:36:55.663] [puff::index::jointLog] [info] Total # of numerical Contigs : 33,539,665\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:37:50.463] [puff::index::jointLog] [info] Total # of contig vec entries: 3,168,747,863\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:37:50.463] [puff::index::jointLog] [info] bits per offset entry 32\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:49:49.133] [puff::index::jointLog] [info] Done constructing the contig vector. 33539666\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:35.601] [puff::index::jointLog] [info] # segments = 33,539,665\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:35.601] [puff::index::jointLog] [info] total length = 436,017,596\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:35.960] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:49.845] [puff::index::jointLog] [info] positional integer width = 29\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:49.845] [puff::index::jointLog] [info] seqSize = 436,017,596\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:49.845] [puff::index::jointLog] [info] rankSize = 436,017,596\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:49.845] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:49.845] [puff::index::jointLog] [info] num keys = 33,541,616\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   0 min 3  sec   remaining:   0 min 0  sec\n",
      "Bitarray       175752960  bits (100.00 %)   (array + ranks )\n",
      "final hash             0  bits (0.00 %) (nb in final hash 0)\n",
      "\u001b[00m[2020-11-24 23:51:52.567] [puff::index::jointLog] [info] mphf size = 20.9514 MB\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk size = 10,900,440\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 0 = [0, 10,900,450)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 1 = [10,900,450, 21,800,901)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 2 = [21,800,901, 32,701,353)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 3 = [32,701,353, 43,601,801)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 4 = [43,601,801, 54,502,252)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 5 = [54,502,252, 65,402,701)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 6 = [65,402,701, 76,303,150)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 7 = [76,303,150, 87,203,601)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 8 = [87,203,601, 98,104,050)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 9 = [98,104,050, 109,004,502)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 10 = [109,004,502, 119,904,953)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 11 = [119,904,953, 130,805,405)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 12 = [130,805,405, 141,705,845)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 13 = [141,705,845, 152,606,293)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 14 = [152,606,293, 163,506,742)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 15 = [163,506,742, 174,407,193)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.653] [puff::index::jointLog] [info] chunk 16 = [174,407,193, 185,307,641)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 17 = [185,307,641, 196,208,093)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 18 = [196,208,093, 207,108,534)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 19 = [207,108,534, 218,008,985)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 20 = [218,008,985, 228,909,436)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 21 = [228,909,436, 239,809,887)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 22 = [239,809,887, 250,710,331)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 23 = [250,710,331, 261,610,772)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 24 = [261,610,772, 272,511,223)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 25 = [272,511,223, 283,411,675)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 26 = [283,411,675, 294,312,127)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 27 = [294,312,127, 305,212,577)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 28 = [305,212,577, 316,113,029)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 29 = [316,113,029, 327,013,478)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 30 = [327,013,478, 337,913,918)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 31 = [337,913,918, 348,814,366)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 32 = [348,814,366, 359,714,807)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 33 = [359,714,807, 370,615,255)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 34 = [370,615,255, 381,515,706)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 35 = [381,515,706, 392,416,147)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 36 = [392,416,147, 403,316,587)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 37 = [403,316,587, 414,217,038)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 38 = [414,217,038, 425,117,484)\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.672] [puff::index::jointLog] [info] chunk 39 = [425,117,484, 436,017,584)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.982] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:52.982] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:51:53.105] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2020-11-24 23:51:54.794] [jLog] [info] done building index\n",
      "salmon index -t gentromes/orfquant_tx.gentrome.fa.gz -d decoys.txt t -p 40 -i indices/orfquant_tx_k31 -k 31 --gencode \n",
      "Version Info: This is the most recent version of salmon.\n",
      "[2020-11-24 23:51:55.053] [jLog] [info] building index\n",
      "out : indices/orfquant_tx_k31\n",
      "\u001b[00m[2020-11-24 23:51:55.054] [puff::index::jointLog] [info] Running fixFasta\n",
      "\u001b[00m\n",
      "[Step 1 of 4] : counting k-mers\n",
      "\n",
      "\u001b[35m[2020-11-24 23:53:10.030] [puff::index::jointLog] [warning] Removed 18 transcripts that were sequence duplicates of indexed transcripts.\n",
      "\u001b[00m\u001b[35m[2020-11-24 23:53:10.030] [puff::index::jointLog] [warning] If you wish to retain duplicate transcripts, please use the `--keepDuplicates` flag\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:53:10.030] [puff::index::jointLog] [info] Replaced 151,122,963 non-ATCG nucleotides\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:53:10.030] [puff::index::jointLog] [info] Clipped poly-A tails from 221 transcripts\n",
      "\u001b[00mwrote 24512 cleaned references\n",
      "\u001b[00m[2020-11-24 23:53:14.433] [puff::index::jointLog] [info] Filter size not provided; estimating from number of distinct k-mers\n",
      "\u001b[00m\u001b[00m[2020-11-24 23:53:50.836] [puff::index::jointLog] [info] ntHll estimated 2622498330 distinct k-mers, setting filter size to 2^36\n",
      "\u001b[00mThreads = 40\n",
      "Vertex length = 31\n",
      "Hash functions = 5\n",
      "Filter size = 68719476736\n",
      "Capacity = 2\n",
      "Files: \n",
      "indices/orfquant_tx_k31/ref_k31_fixed.fa\n",
      "--------------------------------------------------------------------------------\n",
      "Round 0, 0:68719476736\n",
      "Pass\tFilling\tFiltering\n",
      "1\t86\t82\t\n",
      "2\t48\t9\n",
      "True junctions count = 21559583\n",
      "False junctions count = 3485755\n",
      "Hash table size = 25045338\n",
      "Candidate marks count = 350298265\n",
      "--------------------------------------------------------------------------------\n",
      "Reallocating bifurcations time: 10\n",
      "True marks count: 346566115\n",
      "Edges construction time: 48\n",
      "--------------------------------------------------------------------------------\n",
      "Distinct junctions = 21559583\n",
      "\n",
      "allowedIn: 30\n",
      "Max Junction ID: 21560010\n",
      "seen.size():172480089 kmerInfo.size():21560011\n",
      "approximateContigTotalLength: 1202883022\n",
      "counters for complex kmers:\n",
      "(prec>1 & succ>1)=5263193 | (succ>1 & isStart)=114 | (prec>1 & isEnd)=100 | (isStart & isEnd)=5\n",
      "contig count: 36268077 element count: 3744358073 complex nodes: 5263412\n",
      "# of ones in rank vector: 36268076\n",
      "\u001b[00m[2020-11-25 00:05:34.674] [puff::index::jointLog] [info] Starting the Pufferfish indexing by reading the GFA binary file.\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:05:34.674] [puff::index::jointLog] [info] Setting the index/BinaryGfa directory indices/orfquant_tx_k31\n",
      "\u001b[00msize = 3744358073\n",
      "-----------------------------------------\n",
      "| Loading contigs | Time = 447.4 ms\n",
      "-----------------------------------------\n",
      "size = 3744358073\n",
      "-----------------------------------------\n",
      "| Loading contig boundaries | Time = 217.65 ms\n",
      "-----------------------------------------\n",
      "Number of ones: 36268076\n",
      "Number of ones per inventory item: 512\n",
      "Inventory entries filled: 70837\n",
      "36268076\n",
      "\u001b[00m[2020-11-25 00:05:44.233] [puff::index::jointLog] [info] Done wrapping the rank vector with a rank9sel structure.\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:05:44.910] [puff::index::jointLog] [info] contig count for validation: 36,268,076\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:05:59.704] [puff::index::jointLog] [info] Total # of Contigs : 36,268,076\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:05:59.704] [puff::index::jointLog] [info] Total # of numerical Contigs : 36,268,076\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:02.185] [puff::index::jointLog] [info] Total # of contig vec entries: 360,095,721\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:02.185] [puff::index::jointLog] [info] bits per offset entry 29\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:25.357] [puff::index::jointLog] [info] Done constructing the contig vector. 36268077\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:37.776] [puff::index::jointLog] [info] # segments = 36,268,076\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:37.776] [puff::index::jointLog] [info] total length = 3,744,358,073\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:38.160] [puff::index::jointLog] [info] Reading the reference files ...\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:50.872] [puff::index::jointLog] [info] positional integer width = 32\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:50.872] [puff::index::jointLog] [info] seqSize = 3,744,358,073\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:50.872] [puff::index::jointLog] [info] rankSize = 3,744,358,073\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:50.872] [puff::index::jointLog] [info] edgeVecSize = 0\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:06:50.872] [puff::index::jointLog] [info] num keys = 2,656,315,793\n",
      "\u001b[00mfor info, total work write each  : 2.331    total work inram from level 3 : 4.322  total work raw : 25.000 \n",
      "[Building BooPHF]  100  %   elapsed:   1 min 52 sec   remaining:   0 min 0  sec\n",
      "Bitarray     13918249920  bits (100.00 %)   (array + ranks )\n",
      "final hash        647472  bits (0.00 %) (nb in final hash 1927)\n",
      "\u001b[00m[2020-11-25 00:08:42.573] [puff::index::jointLog] [info] mphf size = 1659.26 MB\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk size = 93,608,952\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 0 = [0, 93,608,972)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 1 = [93,608,972, 187,217,924)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 2 = [187,217,924, 280,826,895)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 3 = [280,826,895, 374,435,861)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 4 = [374,435,861, 468,044,819)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 5 = [468,044,819, 561,653,771)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.643] [puff::index::jointLog] [info] chunk 6 = [561,653,771, 655,262,729)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 7 = [655,262,729, 748,871,701)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 8 = [748,871,701, 842,480,653)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 9 = [842,480,653, 936,089,619)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 10 = [936,089,619, 1,029,698,598)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 11 = [1,029,698,598, 1,123,307,550)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 12 = [1,123,307,550, 1,216,916,502)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 13 = [1,216,916,502, 1,310,525,454)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 14 = [1,310,525,454, 1,404,134,406)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 15 = [1,404,134,406, 1,497,743,358)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 16 = [1,497,743,358, 1,591,352,310)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 17 = [1,591,352,310, 1,684,961,262)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 18 = [1,684,961,262, 1,778,570,214)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 19 = [1,778,570,214, 1,872,179,166)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 20 = [1,872,179,166, 1,965,788,118)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 21 = [1,965,788,118, 2,059,397,070)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 22 = [2,059,397,070, 2,153,006,022)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 23 = [2,153,006,022, 2,246,614,974)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 24 = [2,246,614,974, 2,340,223,926)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 25 = [2,340,223,926, 2,433,832,878)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 26 = [2,433,832,878, 2,527,441,840)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 27 = [2,527,441,840, 2,621,050,792)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 28 = [2,621,050,792, 2,714,659,744)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 29 = [2,714,659,744, 2,808,268,696)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 30 = [2,808,268,696, 2,901,877,648)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 31 = [2,901,877,648, 2,995,486,628)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 32 = [2,995,486,628, 3,089,095,580)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 33 = [3,089,095,580, 3,182,704,532)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 34 = [3,182,704,532, 3,276,313,496)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 35 = [3,276,313,496, 3,369,922,448)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 36 = [3,369,922,448, 3,463,531,400)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 37 = [3,463,531,400, 3,557,140,352)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 38 = [3,557,140,352, 3,650,749,315)\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:08:47.644] [puff::index::jointLog] [info] chunk 39 = [3,650,749,315, 3,744,358,043)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[00m\u001b[00m[2020-11-25 00:09:28.969] [puff::index::jointLog] [info] finished populating pos vector\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:09:28.969] [puff::index::jointLog] [info] writing index components\n",
      "\u001b[00m\u001b[00m[2020-11-25 00:09:42.691] [puff::index::jointLog] [info] finished writing dense pufferfish index\n",
      "\u001b[00m[2020-11-25 00:09:44.012] [jLog] [info] done building index\n"
     ]
    }
   ],
   "source": [
    "#now generate a salmon index from each gentrome\n",
    "!mkdir indices\n",
    "import os\n",
    "import subprocess\n",
    "tx_files = ['orfquant_CDS_15_15.fa', 'orfquant_tx.fa']\n",
    "for tx_file in sorted(tx_files):\n",
    "    for k in [13, 31]:\n",
    "        prefix = tx_file[:-3]\n",
    "        gentrome_path = os.path.join('gentromes/', prefix+'.gentrome.fa.gz')\n",
    "        index_path = os.path.join('indices/', prefix)\n",
    "        #use K=31 for RNAseq (~75bp reads, and 13 for profiling)\n",
    "        cmd=\"salmon index -t {gentrome_path} -d decoys.txt t -p 40 -i {index_path}_k{k} -k {k} --gencode \".format(**locals())\n",
    "        #pasted into terminal\n",
    "        print(cmd)\n",
    "        ! {cmd}\n",
    "    #subprocess.Popen(cmd, shell=True).wait()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
